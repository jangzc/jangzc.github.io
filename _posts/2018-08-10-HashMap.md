---
layout:     post
title:      java中哈希表及其应用详解
subtitle:   Java数据结构与算法(八)
date:       2018-08-10
author:     Jang
header-img: img/post-bg-debug.png
catalog: true
tags:
    - Algorithm
---

* 哈希算法，是一类算法
* 哈希表(Hash Table), 一种数据结构
* 哈希函数，是支撑哈希表的一类函数
* Map是映射的意思，在Java中Map表示一种把K映射到V的数据结构
* HashMap, 是Java中用哈希表实现的一种Map

# 1. Hash算法
# 1.1 是什么？
```
这类算法接受任意长度的二进制输入值，对输入值做换算(切碎)，最终给出固定长度的二进制输出值
```
以更好理解的方式来说，Hash算法是摘要算法：它从不同的输入中，通过一些计算摘取出来一段输出结果，且这个值可以用以区分输入数据。
所以，MD5可能是最著名的一种Hash算法了。

# 1.2 有什么用？
* 1. 信息安全领域
Hash算法可用作加密算法。<br>
如文件检验：通过对文件摘要，可以得到文件的数字指纹。
* 2. 数据结构领域
Hash算法通常还可以用作快速查找.
根据Hash函数我们可以实现一种叫做哈希表的数据结构。这种结构可以使得我们可以实现对数据快速的"存"和"取"

# 2. 哈希表
## 2.1 什么是哈希表？
首先想一个问题：我们之前是如何在数据结构中做查找的呢？<br>
* 线性表、树：在线性表、树这些结构中，记录在结构中的相对位置是随机的，和记录的关键字之间不存在确定关系。因此，在结构中查找时需要进行一系列和关键字的比较，即这一类查找方法建立在比较的基础上。在顺序查找时，比较的结果为"="与"!="2种可能；在折半查找、二叉排序操作和B-树查找时，比较的结果为"<","=",">"3种可能。此时，查找的效率依赖于查找过程中所进行的比较次数。<br>
* 引出Hash表：理想的情况是希望不经过任何比较，一次存取便能得到所查记录，那就必须在记录的存储位置和它的关键字之间建立一个确定的关系f,使每个关键字和结构中一个唯一的存储位置相对应。因而在查找时，只要根据这个对应关系f找到给定值K的像f(K)。若结构中存在关键字和K相等的记录，则必定在f(K)的存储位置上，反正在这个位置上没有记录。因此，不需要比较便可直接取得所查记录。在此，我们称这个对应关系f为:哈希函数，按这个思想建立的映射关系表为：哈希表。<br>

哈希函数的特点：
* 1. 灵活
	哈希函数是一个映像，因此哈希函数的设定很灵活，只要使得任何关键字由此所得的哈希函数值都落在表长允许的范围之内即可。
* 2. 冲突
	对不同的关键字可能得到同一哈希地址。<br>
	冲突只能尽量地少，而不能完全避免。因为，哈希函数是从关键字集合到地址集合的映像。而通常关键字集合比较大，它的元素包括所有可能的关键字，而地址集合的元素仅为哈希表的地址值。因此，在实现哈希表这种数据结构的时候不仅到设定一个"好"的哈希函数，而且要设定一种"处理冲突的方法"。<br>
	
哈希表的正式定义：
```
根据设定的Hash函数-H(key)和处理冲突的方法，将一组关键字映像到一个有限的连续的地址集(区间)上，并以关键字在地址集中的像作为记录在表中的存储位置，这样的映射表称为Hash表
```

## 2.2 哈希函数详细描述<br>
上面我们已经引出了并解释了哈希函数，即哈希函数是支撑哈希表的一类函数。实际工作中，需要视不同的情况采用不同的hash函数，通常要考虑的因素有：
* Hash函数执行的时间
* 关键字的长度
* Hash表的大小
* 关键字的分布情况
* 记录的查找频率

有如下一些常用的Hash函数构造方法：
* 1. 直接寻址法:<br>
	f(k) = k 或者 f(k) = a * k + b <br>
	取k或者k的某个线性函数为Hash地址。<br>
	特点: 由于直接地址法相当于有多少个关键字就必须有多少个相应地址去对应，所以不会产生冲突，也正因为此，所以实际中很少使用这种构造方法。<br>
* 2. 数字分析法：<br>
	首先分析待存的一组关键字，比如是一个班级学生的出生年月日，我们发现他们的出生年大体相同，那么我们肯定不能用他们的年来作为存储地址，这样出现冲突的几率很大；但是我们发现月日的具体数字差别很大，如果我们用月日来作为Hash地址，则会明显降低冲突几率。因此数字分析法就是找出关键字的规律，尽可能用差异数据来构造Hash地址<br>
	特点：需要提前知道所有可能的关键字，才能分析运用此种方法，所以不太常用<br>
* 3. 平方取中法:<br>
	先求出关键字的平方值，然后按需要取平方值的中间几位作为哈希地址。这是因为：平方后中间几位和关键字中每一位都相关，故不同关键字会以较高的概率产生不同的哈希地址。<br>
	例如：我们把英文字母在字母表中的位置序号作为该英文字母的内部编码。例如K的内部编码为11, E的内部编码为05, Y的内部编码为25. 由此组成关键字"KEYA"的内部代码为11052501，之后对关键字进行平方运算后，取出第7到第9位为该关键字哈希地址，如下：<br>

		|    关键字    | 内部编码 |内部编码的平方值 |H(k)关键字的哈希地址 |
		| ---------- | --- |--- |--- |
		| KEYA |  11050201 |122157778355001 |778 |
		| KEYB      |  11250102 |126564795010404 |795 |
		| AKEY |  01110525 |001233265775625 |265 |
		| BKEY       |  02110525 |004454315775625 |315 |
	特点：较常用<br>
* 4. 折叠法:<br>
	a将关键字分割成位数相同的几部分(最后一部分位数可以不同)，然后取这几部分的叠加和(去除进位)作为散列地址。数位叠加可以有移位叠加和间界叠加两种方法。移位叠加是将分割后的每一部分的最低位对齐，然后相加；间界叠加是从一端向另一端沿分割界来回折叠，然后对齐相加。<br>
* 5. 随机数法：<br>
	选择一个随机函数，取关键字的随机函数值作为Hash地址，通常用于关键字长度不同的场合。即f(key)=randowm(key)
	特点：通常，关键字长度不相等时，采用此法构建Hash函数较为合适<br>
* 6. 除留取余法: <br>
	f(k) = k mod p, p<=m<br>
	取关键字被某个不大于Hash表长m的数p除后所得的余数为Hash地址
	特点：这是最简单也是最常用的hash函数构造方法。可以直接取模，也可以在平方法、折叠法之后再取模<br>
	值得注意的是，在使用除留取余法时，对p的选择很重要，如果p选得不好会容易产生同义词。由经验得知：p最好选择不大于表长m的一个质数、或者不包含小于20的质因数的合数。

## 2.3 处理冲突<br>
如何处理冲突是哈希造表不可缺少的一个方面。现在描述一下处理冲突：<br>
假设哈希表的地址集为:0 ~ (n-1)，那么冲突是指：由关键字得到的哈希地址为j(0<=j<=n-1)的位置上已存有记录，而处理冲突：就是为该关键字的记录找到另一个空的哈希地址。<br>

在处理冲突的过程中可能得到一个地址序列H<sub>i</sub>,i=1,2,...,k。处理时，若得到的另一个哈希地址H<sub>i</sub>仍然发生冲突，则再求下一个地址H<sub>2</sub>，若H<sub>2</sub>仍然冲突，再继续求...<br>

冲突处理通常有以下4种方法:
* 1. 开放定制法
* 2. 再哈希法
* 3. 链地址法:
	将所有关键字为同义词的记录存储在同一线性表中。即在Hash出来的哈希地址中不直接存Key，而是存储一个Key的链表，当发生冲突时，将同义的Key加入链表
* 4. 公共一处区:
	可以建立一个公共溢出区，用来存放有冲突的Key. 比如设立另一个哈希表，专门用来存放出现冲突的同义词。
	
## 2.4 查找及分析<br>
在哈希表上进行查找的过程和哈希造表的过程基本是一致的。不再赘述<br>
接下来分析一下哈希表的查找长度

* 平均查找长度<br>
虽然哈希表在关键字与记录的存储位置之间建立了直接映像，但由于"冲突"的存在，使得哈希表的查找过程仍然是一个"给定值和关键字进行比较"的过程。因此，仍需以平均查找长度作为衡量哈希表的查找效率的度量<br>

查找过程中，需要"和给定值进行比较的关键字的个数"取决于下列三个因素:
	* a. 哈希函数的好坏
	* b. 处理冲突的方法
	* c. 哈希表的装填因子

* 装填因子<br>
在一般情况下，我们设计的哈希函数肯定是尽量均匀的，没有提升空间了，所以可以不考虑它对平均查找长度的影响。那么对于处理冲突方法相同的哈希表，其平均查找长度就依赖于哈希表的装填因子了。其定义如下:<br>
α=表中填入的记录数/哈希表的长度   装填因子α标志哈希表的装满程度<br>
直观的看:
	* α越小，发生冲突的可能性就越小
	* α越大，代表着表中已填入的元素越多，再填入元素时发生冲突的可能性就越大。那么在查找时，给定值需要比较的关键字的个数就越多。<br>
所以，对于"平均查找长度"我们的结论如下:
```
哈希表的平均查找长度的装填因子α的函数，而不是n的函数。因此，不管n多大，我们总是可以选择一个合适的装填因子以便将平均查找长度限定在一个范围内(Java中HashMap的默认装填因子是0.75)
```

# 3. Java的HashMap<br>
FAQ:<br>
* 1. 为什么要有HashMap?
	* 答：我们非常期待能在Java中使用Hash表这种数据结构，因为它的快速存取特性。
* 2. Hash表和HashMap的关系？
	* 答：Hash表是一种逻辑数据结构，HashMap是Java中的一种数据类型，它通过代码实现了Hash表这种数据结构，并利用此结构实现了Map的功能。去除value部分只看key部分就是一个Hash表了
* 3. 这一章节我们要干嘛？
	* 答：我们是在分析一个叫做哈希表的数据结构吗？不是的！我们是在讨论Java这个高级程序设计语言中一个数据类型Map的实现HashMap,它利用了哈希表这个数据结构但它不是哈希表本身，它就是它自己-HashMap类型。所以，我们再看一次HashMap父接口Map的JavaDoc描述："An object that maps keys to values", 即"Map是一个键值对对象"。
* 4. Java中的数据类型
	* 答：有些话不明白的说出来，其实容易让人想不明白。所以我想说：
		* 实际上，编程语言中数据类型都是层层封装的结果。
		* 实际上，Java中只有3类数据类型: 原生类型(primitive8个)、数组、Object
		* 实际上，无论官方的集合框架也好，你自己创建的类也好，都只能是源自于Object并依赖于原有的这3类数据类型；
		* 最终，到现在你可能才会发现，"数组"这种类型竟是如此的重要，在Java中，如果没有数组作为基础结构，你是不可能构造出任何想实现某种数据结构的Object类型的。

## 3.1 上帝视角的HashMap<br>
* HashMap是基于数组来实现哈希表的，数组就好比内存储空间，数组的index就好比内存的地址<br>
* HashMap中的每个记录就是数组中存储的一个Entry<K,V>对象(链)<br>
* HashMap的哈希函数为f(key)=key.hashCode() & (table.length -1); 这里简化了hasCode的优化部分
* HashMap冲突方法是：链地址法，即每个数组位置上(称为bucket)存放的实际上都是一个Entry链而不是单个对象。这表现在Entry对象都有一个熟悉next来指向链表的下一个Entry<br>
* HashMap的装填因子；默认为0.75<br>
* 基本上HashMap就像下图这样:<br>
<img src="https://img-blog.csdn.net/20160724225743051"/>

## 3.2 创建HashMap-构造函数<br>
```
/*** 1. 构造方法：最终使用的是这个构造方法 ***/

//初始容量initialCapacity为16, 负载因子loadFactor为0.75
public HashMap(int initialCapacity, float loadFactor){
	if (initialCapacity < 0)
		throw new IllegalArgumentException();
	if (initialCapacity > MAXIMUM_CAPACITY)
		initialCapacity = MAXIMUM_CAPACITY;
	if (loadFactor <=0 || Float.isNaN(loadFactor))
		 throw new IllegalArgumentException;
		 
	this.loadFactor = loadFactor;
	threshold = initailCapacity;
	init(); //init可以忽略，方法默认为空{}, 在你需要继续HashMap实现子类时可以重写此方法做一些事情
}

/*** 2. 静态成员变量 ***/

/** 默认的容量，容量必须是2的幂 */
static final int DEFAULT_INITIAL_CAPACITY = 1<<4; //aka 16
/** 最大容量为2的30次方 */
static final int MAXIMUM_CAPACITY = 1<<30;
/** 默认装填因子0.75 */
static final float DEAULT_LOAD_FACTOR = 0.75f;
/** 默认Entry数组 */
static final Entry<?,?>[] EMPTY_TABLE = {};

/** Entry数组:table */
transient Entry<K,V>[] table = (Entry<K,V>[]) EMPTY_TABLE;

/** table中实际的Entry数量 */
transient int size;

/**
* size到达此阀值后，必须扩容
* 值为capacity * load factor, 默认为16 * 0.75 = 12
* 意味着默认构造情况下，当你存够12个时，table会第一次扩容
*/
int threshold;

/** 装填因子，值从一开始构造HashMap时就被确定了，默认为0.75 */
final float loadFactor;

/**
* 哈希种子，实例化HashMap后将要使用前设置的随机值，可以使得key的hashCode冲突更难出现
*/
transient int hashSeed = 0;

/*** 3.Map.Entry<K,V>:数组table中实际存储的类型 ***/
static class Entry<K,V> implements Map.Entry<K,V>{
	final K key;		//"key-Value对"的Key
	V value;			//"Key-Value对"的value
	Entry<K,V> next;	//链表的下一个Entry
	int hash;			//key经过优化后的hash值
	
	Entry(int h, K k, V v, Entry<K,V> n) {
		value = v;
		next = n;
		key = k;
		hash = h;
	}
	
	public final int hasCode() {
		return Object.hashCode(getKey() ^ Objects.hashCode(getValue()));
	}
}
```
* 1. 为什么数组最大长度只能是MAXIMUM_CAPACITY即2^30?<br>
int最大是2^31-1,意味着Java数组的length最大只能为2^31-1，继而数组index最大只能为2^31-2.<br>
进一步，HashMap的哈希函数非常想使用"位运算"而不想使用"取模"，因为位运算快。可是使用位运算时，要求用于运算的p值必须是: 二进制每位都是1, 即2^N-1, 这样所得结果才能铺满数组所有的index.不过依照上一条，index不可能是2^31-1所以不符合要求。<br>
所以，最终我们退一步让index最大为2^30-1，这样MAXIMUM_CAPACITY最大也就只能是2^30-1了
* 2. 为什么成员属性大多用transient修饰?<br>
静态属性不会被序列化所以加transient也没用。而加tansient的那些成员属性不应该被序列化，因为反序列化时它们应该被重新计算而不是使用旧值。

## 3.3 存 - put(key,value)、解决冲突
```
/** 存放 **/
public V put(K key, V value) {
	if (table == EMPTY_TABLE) {
		//数组长度被运算为是2的幂，默认初始长度是16，且hashSeed会被赋值
		inflateTable(threshold);
	}
	
	if (key == null){
		//hashMap允许key为null: 永远放在table中第0个链表上，同时null的hash为0
		return putForNullKey(value);
	}
	
	//1). 计算key的hashCode
	int hash = hash(key);
	
	//2). 根据hashCode计算index
	int i = indexFor(hash, table.length);
	
	//3). 做覆盖，遍历在i位置的entry链表
	for(Entry<K,V> e= table[i]; e!=null; e= e.next){
		Object k;
		if(e.hash == hash && ((k=e.key)==key||key.equals(k))){
			//hashCode和equals都相等则覆盖并return旧value
			V oldValue = e.value;
			e.value = value;
			e.recordAccess(this);
			return oldValue;
		}
	}
	
	modCount++;
	
	//4. 添加Entry，并解决冲突
	//如果需要增加table长度(size>threashold)就乘2增加，并重新计算每个元素所在table中的位置和转移
	addEntry(hash,key,value,i);
	return null;//增加成功最后返回Null
}
```

```
public class MyHashMap<K, V> {

	private static final double LOAD_FACTOR = 0.75;
	private static final int DEFAULT_CAPACITY = 16;

	private Entry[] table;
	private int elemCount;

	class Entry<K, V> {

		private int hash;
		private K key;
		private V value;
		private Entry<K, V> next;

		public Entry(K key, V value) {
			this.key = key;
			this.value = value;
			this.next = null;
		}

		public Entry(int hash, K key, V value, Entry<K, V> next) {
			this.hash = hash;
			this.key = key;
			this.value = value;
			this.next = next;
		}

		public void setHash(int newHash) {
			hash = newHash;
		}

		public void setKey(K newKey) {
			key = newKey;
		}

		public void setValue(V newValue) {
			value = newValue;
		}

		public void setNext(Entry<K, V> newEntry) {
			next = newEntry;
		}

		public int getHash() {
			return hash;
		}

		public K getKey() {
			return key;
		}

		public V getValue() {
			return value;
		}

		public Entry<K, V> getNext() {
			return next;
		}
	}

	public MyHashMap() {
		table = new Entry[DEFAULT_CAPACITY];
		elemCount = 0;
	}

	public MyHashMap(int capacity) {
		table = new Entry[capacity];
		elemCount = 0;
	}

	public V put(K key, V value) {

		int hash = (key == null) ? 0 : hash(key.hashCode());
		int i = indexFor(hash, table.length);
		for (Entry<K, V> e = table[i]; e != null; e = e.getNext()) {
			if (e.getKey().equals(key)) {
				V oldValue = e.getValue();
				e.setValue(value);
				return oldValue;
			}
		}
		addEntry(hash, key, value, i);
		return null;
	}

	public V get(K key) {

		int hash = (key == null) ? 0 : hash(key.hashCode());
		int i = indexFor(hash, table.length);
		for (Entry<K, V> e = table[i]; e != null; e = e.getNext()) {
			if (e.getKey().equals(key)) {
				return e.getValue();
			}
		}
		return null;
	}

	public V remove(K key) {
		int hash = (key == null) ? 0 : hash(key.hashCode());
		int i = indexFor(hash, table.length);

		Entry<K, V> prev = table[i];
		Entry<K, V> e = prev;

		while (e != null) {
			if (e.getKey().equals(key)) {
				if (prev == e) {
					table[i] = e.getNext();
				} else {
					prev.setNext(e.getNext());
				}
				elemCount--;
				return e.getValue();
			}
			prev = e;
			e = e.getNext();
		}
		return null;
	}

	@Override
	public String toString() {
		StringBuilder sb = new StringBuilder();
		for (int i = 0; i < table.length; i++) {
			if (table[i] != null) {
				sb.append(i + ": ");
				Entry<K, V> curr = table[i];
				while (curr != null) {
					sb.append("(" + curr.getKey() + ", " + curr.getValue() + ") ");
					curr = curr.getNext();
				}
				sb.append('\n');
			}
		}
		return sb.toString();
	}

	private int indexFor(int h, int length) {
		return h & (length - 1);
	}

	private void addEntry(int hash, K key, V value, int bucketIndex) {
		Entry<K, V> e = table[bucketIndex];
		table[bucketIndex] = new Entry<K, V>(hash, key, value, e);
		elemCount++;
		if (elemCount >= LOAD_FACTOR * table.length)
			resize();
	}

	private int hash(int h) {
		h ^= (h >>> 20) ^ (h >>> 12);
		h ^= (h >>> 7) ^ (h >>> 4);
		return (h < 0) ? h * -1 : h;
	}

	private void resize() {
		Entry[] newTable = new Entry[table.length * 2];

		for (int j = 0; j < table.length; j++) {
			Entry<K, V> e = table[j];

			if (e != null) {
				while (e != null) {
					Entry<K, V> next = e.getNext();
					int i = indexFor(e.getHash(), newTable.length);
					e.setNext(newTable[i]);
					newTable[i] = e;
					e = next;
				}
			}
		}
		table = newTable;
	}

	private int getHash(K key) {
		char array[] = String.valueOf(key).toCharArray();
		int hash = 0;
		for (char temp : array) {
			hash = hash * 31 + temp;
		}
		return hash;
	}

	public static boolean equal(String left, String right) {
		int n = left.length();
		if (n == right.length()) {
			char v1[] = left.toCharArray();
			char v2[] = right.toCharArray();
			int i = 0;
			while (n-- != 0) {
				if (v1[i] != v2[i])
					return false;
				i++;
			}
			return true;
		}
		return false;
	}

}

```
